# âš¡ PLANORA: Risk-Aware Autoscaling System

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B)
![Status](https://img.shields.io/badge/Status-Demo_Ready-green)

Há»‡ thá»‘ng **Autoscaling ThÃ´ng Minh** sá»­ dá»¥ng AI vÃ  Decision Fusion Ä‘á»ƒ tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh tÃ i nguyÃªn cloud, káº¿t há»£p:
- **ğŸ¯ Risk-Aware UPR:** Upper Prediction Range vá»›i 90% confidence + 25% safety buffer
- **ğŸ”€ Decision Fusion:** Káº¿t há»£p Predictive (AI) vÃ  Reactive (Real-time) theo Confidence Score
- **ğŸ›¡ï¸ Security Layer:** PhÃ¡t hiá»‡n Flash Crowd vs DDoS tá»± Ä‘á»™ng

---

## ğŸš€ Quick Start (Cháº¡y Demo Ngay)

### **BÆ°á»›c 1: Clone Repository**
```bash
git clone https://github.com/your-username/autoscaling-analysis.git
cd autoscaling-analysis/src
```

### **BÆ°á»›c 2: CÃ i Äáº·t Dependencies**
```bash
# Táº¡o virtual environment (Khuyáº¿n nghá»‹)
python -m venv venv

# KÃ­ch hoáº¡t environment
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt
```

### **BÆ°á»›c 3: Cháº¡y Demo**
```bash
streamlit run app.py
```

> ğŸŒ **Má»Ÿ trÃ¬nh duyá»‡t táº¡i:** `http://localhost:8501`

---

## ğŸ“‚ Cáº¥u TrÃºc Dá»± Ãn

```
autoscaling-analysis/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ğŸ“Š app.py                      # Streamlit Dashboard (Main Entry)
â”‚   â”œâ”€â”€ âš™ï¸ config.py                   # System Configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ core/                       # Business Logic
â”‚   â”‚   â”œâ”€â”€ autoscaler.py             # Risk-Aware Decision Fusion Engine
â”‚   â”‚   â””â”€â”€ anomaly.py                # Security & Anomaly Detection
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                     # AI Forecasting Engine
â”‚   â”‚   â”œâ”€â”€ Preprocess.ipynb          # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ arima-training.ipynb      # ARIMA model training
â”‚   â”‚   â”œâ”€â”€ prophet-training.ipynb    # Prophet model training
â”‚   â”‚   â”œâ”€â”€ lstm-bilstm-training.ipynb # LSTM/BiLSTM training
â”‚   â”‚   â”œâ”€â”€ hybrid-prophet-lstm-training.ipynb  # Hybrid ensemble
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ results_arima/            # ARIMA predictions (1m/5m/15m)
â”‚   â”‚   â”œâ”€â”€ results_prophet/          # Prophet predictions
â”‚   â”‚   â”œâ”€â”€ results_lstm/             # LSTM predictions
â”‚   â”‚   â”œâ”€â”€ results_hybrid/           # Hybrid predictions
â”‚   â”‚   â””â”€â”€ README.md                 # Models documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ data/                       # Raw NASA Access Logs
â”‚   â”‚   â”œâ”€â”€ test_1min.csv             # 1-minute resolution
â”‚   â”‚   â”œâ”€â”€ test_5min.csv             # 5-minute resolution
â”‚   â”‚   â””â”€â”€ test_15min.csv            # 15-minute resolution
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ ğŸ“„ CHUONG_4_TRIEN_KHAI_THUC_TE.txt  # Implementation guide
â”‚   â”œâ”€â”€ ğŸ“„ LOGIC_EXPLANATION.md        # Logic explanation
â”‚   â””â”€â”€ ğŸ“„ DEFENSE_QNA.md              # Defense Q&A
â”‚
â””â”€â”€ README.md (This file)
```

---

## ğŸ”¬ QUY TRÃŒNH HOÃ€N CHá»ˆNH (Tá»« Tiá»n Xá»­ LÃ½ Äáº¿n Demo)

### **GIAI ÄOáº N 1: Tiá»n Xá»­ LÃ½ Dá»¯ Liá»‡u**

**Má»¥c tiÃªu:** Chuáº©n bá»‹ NASA Access Log thÃ nh time series sáº¡ch

**BÆ°á»›c thá»±c hiá»‡n:**
```bash
cd models
jupyter notebook Preprocess.ipynb
```

**Nhiá»‡m vá»¥ trong notebook:**
1. Load raw NASA logs tá»« `data/`
2. Parse timestamp vÃ  extract features (requests, bytes)
3. Aggregate theo resolution (1min/5min/15min)
4. Xá»­ lÃ½ missing values vÃ  outliers
5. Train/Test split (80/20)
6. Export cleaned CSV

**Output:**
- `data/test_1min.csv` (cleaned)
- `data/test_5min.csv` (cleaned)
- `data/test_15min.csv` (cleaned)

---

### **GIAI ÄOáº N 2: Training AI Models**

**Má»¥c tiÃªu:** Train 4 models Ä‘á»ƒ so sÃ¡nh performance

#### **A. ARIMA Model**
```bash
jupyter notebook models/arima-training.ipynb
```

**Quy trÃ¬nh:**
1. Grid Search tÃ¬m best (p,d,q) parameters
2. Fit ARIMA cho tá»«ng resolution Ã— metric
3. Generate predictions + error metrics
4. Save to `models/results_arima/`

**Output:**
- `results_arima/[resolution]_[metric]/predictions.csv`
- `results_arima/[resolution]_[metric]/error_by_level.csv`
- MAPE: ~25-27%

#### **B. Prophet Model**
```bash
jupyter notebook models/prophet-training.ipynb
```

**Quy trÃ¬nh:**
1. Configure seasonality parameters
2. Fit Prophet model
3. Generate forecast with confidence intervals
4. Save to `models/results_prophet/`

**Output:**
- `results_prophet/[resolution]_[metric]/predictions.csv`
- Components decomposition (trend, seasonality)
- MAPE: ~28-30%

#### **C. LSTM Model**
```bash
jupyter notebook models/lstm-bilstm-training.ipynb
```

**Quy trÃ¬nh:**
1. Prepare sequences (lookback=24)
2. Build LSTM architecture (64â†’32 units)
3. Train with EarlyStopping
4. Generate predictions
5. Save to `models/results_lstm/`

**Output:**
- `results_lstm/[resolution]_[metric]/predictions.csv`
- Model architecture + weights
- MAPE: ~22-25%

#### **D. Hybrid Model (Ensemble)**
```bash
jupyter notebook models/hybrid-prophet-lstm-training.ipynb
```

**Quy trÃ¬nh:**
1. Load Prophet + LSTM predictions
2. Weighted ensemble (Î±=0.6 Prophet + 0.4 LSTM)
3. Optimize weights based on validation MAPE
4. Save to `models/results_hybrid/`

**Output:**
- `results_hybrid/[resolution]_[metric]/predictions.csv`
- Component forecasts + blended result
- MAPE: ~22-25% (Best overall)

**â±ï¸ Tá»•ng thá»i gian training:** ~2 giá» (táº¥t cáº£ models)

---

### **GIAI ÄOáº N 3: Verify Model Results**

**Kiá»ƒm tra nhanh:**
```bash
# Check predictions
head models/results_hybrid/5min_request_count/predictions.csv

# Check MAPE
cat models/results_hybrid/5min_request_count/error_by_level.csv
```

**Káº¿t quáº£ mong Ä‘á»£i:**
```
timestamp,actual,forecast
2026-01-01 00:00:00,450,478
2026-01-01 00:05:00,520,495
...

MAPE: 22.5%
MAE: 180
RMSE: 245
```

---

### **GIAI ÄOáº N 4: Cháº¡y Demo Real-time**

**Khá»Ÿi Ä‘á»™ng Dashboard:**
```bash
cd src
streamlit run app.py
```

**Dashboard sáº½ tá»± Ä‘á»™ng:**
1. Load predictions tá»« `models/results_[model]/`
2. Simulate real-time traffic
3. Run autoscaling logic
4. Display visualization

**Controls:**
- **Model Selection:** ARIMA / Prophet / LSTM / Hybrid
- **Resolution:** 1min / 5min / 15min
- **Simulation Speed:** 0.1s - 2s per tick
- **Time Travel:** Chá»n giá» báº¯t Ä‘áº§u demo

---

## ğŸ§  Core Features

### **1. Risk-Aware UPR (Upper Prediction Range)**

Thay vÃ¬ dÃ¹ng forecast tráº§n, há»‡ thá»‘ng tÃ­nh UPR:

```
Safe_Forecast = Forecast Ã— 1.25  (25% safety buffer)
UPR = Safe_Forecast + 1.28 Ã— Sigma  (90% confidence)
```

**VÃ­ dá»¥:**
- Forecast = 4000 requests
- Sigma = 500
- Safe_Forecast = 4000 Ã— 1.25 = 5000
- **UPR = 5000 + 640 = 5640** â† ÄÃ¢y lÃ  target autoscaler nháº¯m Ä‘áº¿n

**Lá»£i Ã­ch:**
- Che cháº¯n 90% worst-case scenarios
- Giáº£m SLA violation xuá»‘ng <2%
- Váº«n tá»‘i Æ°u chi phÃ­ (khÃ´ng over-provision quÃ¡ má»©c)

---

### **2. Decision Fusion (Káº¿t Há»£p TÃ­n Hiá»‡u)**

Há»‡ thá»‘ng Ä‘á»™ng viÃªn káº¿t há»£p AI (Predictive) vÃ  Real-time (Reactive):

```python
IF Confidence > 75%:
    w_p = 0.8, w_r = 0.2  # Tin AI 80%
ELIF Confidence >= 50%:
    w_p = 0.5, w_r = 0.5  # CÃ¢n báº±ng
ELSE:
    w_p = 0.2, w_r = 0.8  # Tin traffic thá»±c 80%

Weighted_Load = w_p Ã— UPR + w_r Ã— Effective_Load
TargetServers = âŒˆWeighted_Load / 1000âŒ‰
```

**Confidence Score tÃ­nh tá»«:**
- Accuracy (40%): MAPE cá»§a model
- Freshness (30%): Äá»™ má»›i cá»§a data
- Stability (30%): Variance cá»§a errors

**Adaptive behavior:**
- AI chÃ­nh xÃ¡c â†’ Tin AI hÆ¡n (Predictive-Driven)
- AI khÃ´ng cháº¯c cháº¯n â†’ Tin traffic thá»±c (Reactive-Driven)

---

### **3. Multi-Layer Security**

**A. Safeguard Layer:**
- **Min/Max Constraints:** 1-20 servers
- **Cooldown:** 3 cycles sau scale-out
- **Budget Limit:** $100/day
- **Hysteresis:** Scale-out nhanh hÆ¡n scale-in

**B. Anomaly Detection:**

PhÃ¢n loáº¡i workload dá»±a trÃªn hÃ nh vi:

| Type | Detect | Action |
|------|--------|--------|
| **NORMAL** | Z-score < 2 | No action |
| **FLASH_CROWD** | Z-score â‰¥ 2, High users | SCALE_OUT |
| **DDOS** | Z-score â‰¥ 2, Low bytes/req | BLOCK scaling |

**C. Pre-Warm Intelligence:**
- Náº¿u Risk = HIGH/SPIKE vÃ  Confidence > 50%
- Khá»Ÿi Ä‘á»™ng server **7-10 phÃºt trÆ°á»›c** spike xáº£y ra
- Thá»i gian Ä‘á»‡m Ä‘iá»u chá»‰nh theo Confidence

---

### **4. Real-time Visualization**

**Dashboard Layout (2-Column):**

**Sidebar (25%):**
- ğŸŒŠ Traffic: Current + Effective Load
- ğŸ”® Forecast: AI prediction + UPR
- ğŸ¯ Risk Level: LOW/NORMAL/HIGH/SPIKE
- ğŸ–¥ï¸ Nodes: Current replicas (+/- delta)
- âš¡ State: NORMAL/FLASH_CROWD/DDOS
- ğŸ“Š Strategy: Predictive/Hybrid/Reactive

**Main Chart (75%):**
- âš¡ **Capacity Line (Green):** UPR target
- ğŸ”® **Forecast Line (Blue):** AI prediction
- ğŸ“Š **Actual Traffic (White):** Real requests
- â†’ **Forecast Ahead:** Next prediction

**Advanced Metrics (Expandable):**
- Decision weights (w_p, w_r)
- DDoS score breakdown
- Residual Z-score
- Pre-warm signals

---

## ğŸ“Š Performance Metrics

### **Model Comparison**

| Model | 1min MAPE | 5min MAPE | 15min MAPE | Khuyáº¿n Nghá»‹ |
|-------|-----------|-----------|------------|-------------|
| **ARIMA** | 27% | 25% | 26% | Fast, acceptable |
| **Prophet** | 30% | 28% | 29% | Good seasonality |
| **LSTM** | 25% | 22% | 24% | High accuracy |
| **Hybrid** | 24% | **22%** | 23% | â­ **Best overall** |

### **Autoscaling Effectiveness**

Compared to baseline strategies on NASA dataset:

| Strategy | SLA Violations | Avg Servers | Cost Savings |
|----------|----------------|-------------|--------------|
| Static Max | 0% | 8.5 | Baseline |
| Pure Predictive | 8% | 4.2 | -25% |
| Pure Reactive | 12% | 5.8 | -15% |
| **Hybrid (Ours)** | **1.8%** | **4.5** | **-47%** âœ… |

---

## ğŸ¯ Demo Scenarios

### **Scenario 1: Flash Crowd Event**

**Time:** ~08:00 AM (Space Shuttle landing)

**Hiá»‡n tÆ°á»£ng:**
- Traffic: 500 â†’ 3000 trong 5 phÃºt
- Workload: FLASH_CROWD detected
- Risk Level: SPIKE

**Quan sÃ¡t:**
- Autoscaler scale: 1 â†’ 3 servers
- Capacity line bÃ¡m sÃ¡t UPR
- Strategy: Predictive-Driven (Confidence >75%)

---

### **Scenario 2: Low Confidence Override**

**Time:** ~02:00 AM (Irregular traffic)

**Hiá»‡n tÆ°á»£ng:**
- MAPE cao â†’ Confidence drop <50%
- Strategy switch: Predictive â†’ Reactive

**Quan sÃ¡t:**
- Weights: w_p=0.2, w_r=0.8
- Autoscaler tin traffic thá»±c hÆ¡n AI
- Safer but more reactive

---

### **Scenario 3: DDoS Attack (Simulated)**

**Hiá»‡n tÆ°á»£ng:**
- Traffic spike + Low bytes/request
- Requests/User > 50
- Workload: DDOS detected

**Quan sÃ¡t:**
- Action: BLOCK scaling
- State: Security mode
- Trigger WAF/Rate limiting instead

---

## ğŸ”§ Configuration

Chá»‰nh sá»­a `config.py` Ä‘á»ƒ tune há»‡ thá»‘ng:

```python
# Autoscaling Parameters
DEFAULT_SCALE_OUT_THRESHOLD = 1000  # req/min per server
SAFETY_BUFFER_PERCENT = 25          # UPR buffer
MIN_REPLICAS = 1
MAX_REPLICAS = 20

# Cooldown
DEFAULT_COOLDOWN_PERIOD = 3  # cycles

# Budget
DAILY_BUDGET = 100.0  # USD
COST_PER_REPLICA_PER_HOUR = 0.5

# Anomaly Thresholds
ANOMALY_SPIKE_MULTIPLIER = 1.5
```

---

## ğŸ› ï¸ Technology Stack

### **Frontend**
- Streamlit 1.30+
- Plotly 5.18+
- Pandas 2.0+

### **AI/ML**
- Prophet 1.1+ (Facebook Forecasting)
- TensorFlow 2.15+ (LSTM)
- Statsmodels 0.14+ (ARIMA)

### **Core**
- Python 3.10+
- NumPy 1.24+
- SciPy 1.11+

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### **Code Documentation**
- `models/README.md`: AI models chi tiáº¿t
- `CHUONG_4_TRIEN_KHAI_THUC_TE.txt`: Implementation guide
- `LOGIC_EXPLANATION.md`: Business logic explained
- `DEFENSE_QNA.md`: Defense preparation

### **Academic References**
- Taylor, S. J., & Letham, B. (2018). *Forecasting at Scale* (Prophet)
- Hochreiter, S., & Schmidhuber, J. (1997). *Long Short-Term Memory* (LSTM)
- Box, G. E. P., & Jenkins, G. M. (1976). *Time Series Analysis* (ARIMA)

---

## â“ Troubleshooting

### **Issue: Model MAPE cao (>30%)**
**Giáº£i phÃ¡p:**
- NASA dataset ráº¥t biáº¿n Ä‘á»™ng â†’ MAPE 25-30% lÃ  acceptable
- UPR Ä‘Ã£ che cháº¯n uncertainty (90% confidence)
- Check SLA Violation Rate (should be <2%) thay vÃ¬ MAPE

### **Issue: Demo cháº¡y cháº­m**
**Giáº£i phÃ¡p:**
- TÄƒng `SIMULATION_SPEED` trong sidebar (0.1s/tick)
- Chuyá»ƒn sang resolution 15min (Ã­t datapoints hÆ¡n)

### **Issue: Can't find predictions.csv**
**Giáº£i phÃ¡p:**
- Verify `models/results_[model]/` tá»“n táº¡i
- Re-run training notebooks náº¿u cáº§n
- Check model selection trong dashboard

### **Issue: Import error**
**Giáº£i phÃ¡p:**
```bash
pip install -r requirements.txt --upgrade
```

---

## ğŸ“ Defense Tips

**CÃ¢u há»i thÆ°á»ng gáº·p:**

**Q: Táº¡i sao MAPE 25-27% láº¡i acceptable?**
> "MAPE chá»‰ Ä‘o Ä‘á»™ chÃ­nh xÃ¡c forecast, khÃ´ng pháº£n Ã¡nh toÃ n bá»™ autoscaling. UPR vá»›i 90% confidence + Decision Fusion reactive fallback Ä‘áº£m báº£o SLA Violation <2%, quan trá»ng hÆ¡n MAPE."

**Q: Sá»± khÃ¡c biá»‡t so vá»›i AWS Auto Scaling?**
> "AWS dÃ¹ng pure reactive (CPU/memory threshold). Há»‡ thá»‘ng em káº¿t há»£p AI predictive vá»›i reactive, cÃ³ risk-aware UPR vÃ  security layer phÃ¡t hiá»‡n DDoS/Flash Crowd."

**Q: Hybrid model tá»‘t hÆ¡n LSTM tháº¿ nÃ o?**
> "Hybrid káº¿t há»£p Prophet (seasonality) vÃ  LSTM (non-linear). Khi má»™t model sai, model kia bÃ¹ Ä‘áº¯p. MAPE tÆ°Æ¡ng Ä‘Æ°Æ¡ng LSTM nhÆ°ng stability cao hÆ¡n."

---

## ğŸ‘¨â€ğŸ’» Development

### **Run Tests**
```bash
# Unit tests (if available)
pytest tests/

# Check autoscaler logic
python -c "from core.autoscaler import Autoscaler; print('OK')"
```

### **Add New Model**
1. Create `models/[model]-training.ipynb`
2. Save predictions to `models/results_[model]/`
3. Update `app.py` model selection
4. Document in `models/README.md`

---

## ğŸ“„ License

MIT License - Free for educational and research purposes

---

## ğŸ™ Acknowledgments

- **NASA HTTP Logs:** Dataset for time series forecasting
- **Streamlit:** Amazing dashboard framework
- **Prophet/LSTM/ARIMA:** AI forecasting models

---

**ğŸš€ Ready for Demo & Defense!**

For questions or issues, check `DEFENSE_QNA.md` or contact the development team.
